{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_modelfit_nocv(params, dtrain, dvalid, predictors, target='target', objective='binary', metrics='auc',\n",
    "                      feval=None, early_stopping_rounds=20, num_boost_round=3000, verbose_eval=10,\n",
    "                      categorical_features=None):\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric': metrics,\n",
    "        'learning_rate': 0.01,\n",
    "        # 'is_unbalance': 'true',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 31,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': -1,  # -1 means no limit\n",
    "        'min_child_samples': 20,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.6,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 0,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.3,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'metric': metrics\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params,\n",
    "                     xgtrain,\n",
    "                     valid_sets=[xgtrain, xgvalid],\n",
    "                     valid_names=['train', 'valid'],\n",
    "                     evals_result=evals_results,\n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10,\n",
    "                     feval=feval)\n",
    "\n",
    "    n_estimators = bst1.best_iteration\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"n_estimators : \", n_estimators)\n",
    "    print(metrics + \":\", evals_results['valid'][metrics][n_estimators - 1])\n",
    "\n",
    "    return bst1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n"
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "    'click_id': 'uint32'\n",
    "}\n",
    "print('loading train data...')\n",
    "train_df = pd.read_csv('/Users/mlx/Downloads/Document/talking_data/train_sample.csv', dtype=dtypes,\n",
    "                       usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting new time-related features...\n"
     ]
    }
   ],
   "source": [
    "print('Extracting new time-related features...')\n",
    "train_df['second'] = pd.to_datetime(train_df.click_time).dt.second.astype('uint8')\n",
    "train_df['minute'] = pd.to_datetime(train_df.click_time).dt.minute.astype('uint8')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "train_df['month'] = pd.to_datetime(train_df.click_time).dt.month.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = len(train_df)\n",
    "r_size = total // 4\n",
    "val_df = train_df[:r_size]\n",
    "train_df = train_df[r_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing validation datasets\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttrain's auc: 0.993087\tvalid's auc: 0.966497\n",
      "[20]\ttrain's auc: 0.997953\tvalid's auc: 0.95894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mlx/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/mlx/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain's auc: 0.998722\tvalid's auc: 0.953376\n",
      "[40]\ttrain's auc: 0.999206\tvalid's auc: 0.953392\n",
      "[50]\ttrain's auc: 0.999489\tvalid's auc: 0.940056\n",
      "[60]\ttrain's auc: 0.999701\tvalid's auc: 0.934006\n",
      "[70]\ttrain's auc: 0.999801\tvalid's auc: 0.928214\n",
      "[80]\ttrain's auc: 0.999902\tvalid's auc: 0.923562\n",
      "[90]\ttrain's auc: 0.999965\tvalid's auc: 0.914762\n",
      "[100]\ttrain's auc: 0.999985\tvalid's auc: 0.90927\n",
      "[110]\ttrain's auc: 0.999997\tvalid's auc: 0.905816\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttrain's auc: 0.993087\tvalid's auc: 0.966497\n",
      "\n",
      "Model Report\n",
      "n_estimators :  10\n",
      "auc: 0.966497107426\n"
     ]
    }
   ],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['ip', 'app', 'device', 'os', 'channel', 'second', 'minute','hour', 'day', 'month']\n",
    "categorical = ['ip', 'app', 'device', 'os', 'channel', 'second', 'minute','hour', 'day', 'month']\n",
    "params = {\n",
    "    'learning_rate': 0.15,\n",
    "    # 'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "    'num_leaves': 12,  # 2^max_depth - 1\n",
    "    'max_depth': 4,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'scale_pos_weight': 99  # because training data is extremely unbalanced\n",
    "}\n",
    "\n",
    "bst = lgb_modelfit_nocv(params,\n",
    "                        train_df,\n",
    "                        val_df,\n",
    "                        predictors,\n",
    "                        target,\n",
    "                        objective='binary',\n",
    "                        metrics='auc',\n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=True,\n",
    "                        num_boost_round=500,\n",
    "                        categorical_features=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/mlx/Downloads/Document/talking_data/test.csv', dtype=dtypes,\n",
    "                      usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['second'] = pd.to_datetime(test_df.click_time).dt.second.astype('uint8')\n",
    "test_df['minute'] = pd.to_datetime(test_df.click_time).dt.minute.astype('uint8')\n",
    "test_df['hour'] = pd.to_datetime(test_df.click_time).dt.hour.astype('uint8')\n",
    "test_df['day'] = pd.to_datetime(test_df.click_time).dt.day.astype('uint8')\n",
    "test_df['month'] = pd.to_datetime(test_df.click_time).dt.month.astype('uint8')\n",
    "test_df['click_id'] = test_df['click_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['is_attributed'] = bst.predict(test_df[predictors])\n",
    "test_df.to_csv('baseline_balanced99.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[['click_id', 'is_attributed']].to_csv('baseline_balanced99.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_2 = pd.read_csv('/Users/mlx/Downloads/Document/talking_data/train_sample.csv', dtype=dtypes,\n",
    "                       usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._iLocIndexer at 0x1a1056ea58>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_size = 10\n",
    "sample_idx = random.sample(range(100), r_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
